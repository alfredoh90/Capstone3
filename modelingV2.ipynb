{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredoh90/Capstone3/blob/main/modelingV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN1ogrTMlHZX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "seed = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiSlC-y1lU5j"
      },
      "outputs": [],
      "source": [
        "# Importing Keras\n",
        "from keras.models import Sequential                          # Neural network model as a sequence of layers.\n",
        "from keras.layers import Conv2D                              # Convolutional layer\n",
        "from keras.layers import MaxPooling2D                        # Max pooling layer\n",
        "from keras.layers import Flatten                             # Layer used to flatten 2D arrays for fully-connected layers.\n",
        "from keras.layers import Dense                               # This layer adds fully-connected layers to the neural network.\n",
        "from keras.layers import Dropout                             # This serves to prevent overfitting by dropping out a random set of activations.\n",
        "from keras.layers import BatchNormalization                  # This is used to normalize the activations of the neurons.\n",
        "from keras.layers import Activation                          # Layer for activation functions\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint   # Classes used to save weights and stop training when improvements reach a limit\n",
        "from keras.models import load_model                          # This helps us to load trained models\n",
        "# Preprocessing layers\n",
        "from keras.layers import Rescaling                           # This layer rescales pixel values\n",
        "\n",
        "# Importing TensorFlow\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-64XGNzSr84"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntGuhyIqlsgN",
        "outputId": "7094c257-dcf8-4dd5-e03f-05ad6b5da100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GPU Found! Using GPU...\n"
          ]
        }
      ],
      "source": [
        "# Configuring GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if True :#gpus:\n",
        "    try:\n",
        "        #for gpu in gpus:\n",
        "            #tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        strategy = tf.distribute.OneDeviceStrategy(device =\"/gpu:0\")\n",
        "        print('\\nGPU Found! Using GPU...')\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "#else:\n",
        "    #strategy = tf.distribute.get_strategy() #remove to try to use the GPU\n",
        "    #print('Number of replicas:', strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brtBnrDPlXWb",
        "outputId": "9a02f69a-593d-4a7a-89a9-312289c0bbae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12019 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Creating a Dataset for the Training data\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"drive/MyDrive/Capstone3/data/train\",  # Directory where the Training images are located\n",
        "    labels = 'inferred', # Classes will be inferred according to the structure of the directory\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['pos', 'neg'], #extensions of the folders holding the classes\n",
        "    batch_size = 16,    # Number of processed samples before updating the model's weights\n",
        "    image_size = (400, 400), # Defining a fixed dimension for all images\n",
        "    shuffle = True,  # Shuffling data\n",
        "    seed = seed,  # Random seed for shuffling and transformations\n",
        "    validation_split = 0, # We don't need to create a validation set from the training set\n",
        "    crop_to_aspect_ratio = True # Resize images without aspect ratio distortion\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIAnGOKSHt-g",
        "outputId": "07ae9399-f35e-4be8-db56-d3d879d2292e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3629 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Creating a Dataset for the Test data\n",
        "testing = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"drive/MyDrive/Capstone3/data/test\",  # Directory where the Training images are located\n",
        "    labels = 'inferred', # Classes will be inferred according to the structure of the directory\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['pos', 'neg'], #extensions of the folders holding the classes\n",
        "    batch_size = 16,    # Number of processed samples before updating the model's weights\n",
        "    image_size = (400, 400), # Defining a fixed dimension for all images\n",
        "    shuffle = True,  # Shuffling data\n",
        "    seed = seed,  # Random seed for shuffling and transformations\n",
        "    validation_split = 0, # We don't need to create a validation set from the training set\n",
        "    crop_to_aspect_ratio = True # Resize images without aspect ratio distortion\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK3KVWnNlY4I",
        "outputId": "74cea7e0-e3bd-4117-aa10-2e6f3177c047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Dataset: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 400, 400, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n",
            "\n",
            "Training Dataset: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 400, 400, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print('\\nTraining Dataset:', train)\n",
        "print('\\nTraining Dataset:', testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmGs_7Oklbuj"
      },
      "source": [
        "We are getting the results of how the data is going to be reviewed:\n",
        "<ul>\n",
        "    <li>Data is going to be returned in batches</li>\n",
        "    <li><b>TensorSpec(shape=(None, 400, 400, 3), dtype=tf.uint8, name=None)</b> represents the features. None represents the batch size, which is None here because it can vary depending on how many samples we have in the last batch; 400, 400 represents the height and width of the images; 3 is the number of channels in the images, indicating they are RGB images. Last, dtype=tf.unit8 tells us that the data type of the image pixels is an unsigned integer of 8 bits.</li>\n",
        "    <li><b>TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)</b> represents the labels in our dataset. Here, None refers to the batch size; 2 refers to the number of labels in the dataset; whilst dtype=tf.float32 is also a 32-bit floating point. </li>\n",
        "</ul>\n",
        "\n",
        "The next step for preprocessing is ensuring that the pixel values of our images are within a 0 to 1 range. First lest confirm the minimum and maximum pixel value for the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp3u08cOld2E"
      },
      "outputs": [],
      "source": [
        "# Checking minimum and maximum pixel values in the training and testing dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for img, label in train:\n",
        "    batch_min = tf.reduce_min(img)\n",
        "    batch_max = tf.reduce_max(img)\n",
        "\n",
        "    min_value = min(min_value, batch_min.numpy())\n",
        "    max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Training dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Training dataset', max_value)\n",
        "\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "for img, label in testing:\n",
        "    batch_min = tf.reduce_min(img)\n",
        "    batch_max = tf.reduce_max(img)\n",
        "\n",
        "    min_value = min(min_value, batch_min.numpy())\n",
        "    max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Testing dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Testing dataset', max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq3Bz0ydlhjd"
      },
      "outputs": [],
      "source": [
        "scaler = Rescaling(1./255) # Defining scaler values between 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BhkrM25liuS"
      },
      "outputs": [],
      "source": [
        "# Rescaling datasets\n",
        "train = train.map(lambda x, y: (scaler(x), y))\n",
        "testing = testing.map(lambda x, y: (scaler(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyyiisexljYy"
      },
      "outputs": [],
      "source": [
        "# Checking minimum and maximum pixel values in the training dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for img, label in train:\n",
        "    batch_min = tf.reduce_min(img)\n",
        "    batch_max = tf.reduce_max(img)\n",
        "\n",
        "    min_value = min(min_value, batch_min.numpy())\n",
        "    max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Validation dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Validation dataset', max_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6tN3f2DloWj"
      },
      "source": [
        "After scaling, it looks like the pixels are withing the 0 and 1 range and we can now continue with building the model. To build the Convolutional Neural Network with Keras, we are going to use the <i>Sequential</i> class. This class allows us to build a linear stack of layers, which is essential for the creation of neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLbD1JZUlpcE"
      },
      "outputs": [],
      "source": [
        "# Creating data augmentation pipeline\n",
        "augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomRotation(\n",
        "        factor = (-.25, .3),\n",
        "        fill_mode = 'reflect',\n",
        "        interpolation = 'bilinear',\n",
        "        seed = seed),\n",
        "\n",
        "\n",
        "        tf.keras.layers.RandomBrightness(\n",
        "        factor = (-.45, .45),\n",
        "        value_range = (0.0, 1.0),\n",
        "        seed = seed),\n",
        "\n",
        "        tf.keras.layers.RandomContrast(\n",
        "        factor = (.5),\n",
        "        seed = seed)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAJegioMlzzv"
      },
      "outputs": [],
      "source": [
        "# Defining an Early Stopping and Model Checkpoints\n",
        "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
        "                              patience = 5, mode = 'max',\n",
        "                              restore_best_weights = True)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.keras',\n",
        "                            monitor = 'val_accuracy',\n",
        "                            save_best_only = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDwqt8zqlu2W",
        "outputId": "a29f4e7f-4559-4b5d-fb91-b35c788ea59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 254ms/step - accuracy: 0.6653 - loss: 2.3487 - val_accuracy: 0.7884 - val_loss: 0.9207\n",
            "Epoch 2/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8162 - loss: 0.4717 - val_accuracy: 0.8380 - val_loss: 1.4569\n",
            "Epoch 3/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8428 - loss: 0.4327 - val_accuracy: 0.8393 - val_loss: 1.4782\n",
            "Epoch 4/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8487 - loss: 0.4136 - val_accuracy: 0.8184 - val_loss: 1.6180\n",
            "Epoch 5/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8555 - loss: 0.4033 - val_accuracy: 0.8071 - val_loss: 3.2350\n",
            "Epoch 6/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8633 - loss: 0.3954 - val_accuracy: 0.8148 - val_loss: 2.8935\n",
            "Epoch 7/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8654 - loss: 0.3756 - val_accuracy: 0.8121 - val_loss: 0.9599\n",
            "Epoch 8/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8657 - loss: 0.3922 - val_accuracy: 0.8482 - val_loss: 1.0052\n",
            "Epoch 9/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8699 - loss: 0.3712 - val_accuracy: 0.8570 - val_loss: 1.3685\n",
            "Epoch 10/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8721 - loss: 0.3629 - val_accuracy: 0.8553 - val_loss: 0.6562\n",
            "Epoch 11/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8742 - loss: 0.3464 - val_accuracy: 0.8603 - val_loss: 0.5797\n",
            "Epoch 12/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8791 - loss: 0.3328 - val_accuracy: 0.8804 - val_loss: 0.6347\n",
            "Epoch 13/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8807 - loss: 0.3512 - val_accuracy: 0.8777 - val_loss: 0.5265\n",
            "Epoch 14/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8780 - loss: 0.3322 - val_accuracy: 0.8961 - val_loss: 0.3388\n",
            "Epoch 15/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8855 - loss: 0.3141 - val_accuracy: 0.8867 - val_loss: 0.4529\n",
            "Epoch 16/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8774 - loss: 0.3224 - val_accuracy: 0.8878 - val_loss: 0.4273\n",
            "Epoch 17/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8869 - loss: 0.3168 - val_accuracy: 0.8766 - val_loss: 0.4134\n",
            "Epoch 18/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.8858 - loss: 0.3039 - val_accuracy: 0.8564 - val_loss: 0.5233\n",
            "Epoch 19/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8881 - loss: 0.3065 - val_accuracy: 0.9002 - val_loss: 0.4039\n",
            "Epoch 20/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8979 - loss: 0.2961 - val_accuracy: 0.8790 - val_loss: 0.4463\n",
            "Epoch 21/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8854 - loss: 0.3030 - val_accuracy: 0.8573 - val_loss: 0.5141\n",
            "Epoch 22/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8934 - loss: 0.2898 - val_accuracy: 0.9113 - val_loss: 0.3716\n",
            "Epoch 23/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8947 - loss: 0.2840 - val_accuracy: 0.8713 - val_loss: 0.4450\n",
            "Epoch 24/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8960 - loss: 0.3115 - val_accuracy: 0.8192 - val_loss: 0.6789\n",
            "Epoch 25/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8955 - loss: 0.3050 - val_accuracy: 0.9049 - val_loss: 0.2873\n",
            "Epoch 26/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8974 - loss: 0.2859 - val_accuracy: 0.9115 - val_loss: 0.2991\n",
            "Epoch 27/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8968 - loss: 0.3004 - val_accuracy: 0.9093 - val_loss: 0.3025\n",
            "Epoch 28/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8932 - loss: 0.2851 - val_accuracy: 0.8840 - val_loss: 0.3701\n",
            "Epoch 29/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.9009 - loss: 0.2716 - val_accuracy: 0.8741 - val_loss: 0.4606\n",
            "Epoch 30/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.9031 - loss: 0.2599 - val_accuracy: 0.8597 - val_loss: 0.4064\n",
            "Epoch 31/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.9042 - loss: 0.2686 - val_accuracy: 0.9184 - val_loss: 0.2779\n",
            "Epoch 32/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.9023 - loss: 0.2923 - val_accuracy: 0.9027 - val_loss: 0.2642\n",
            "Epoch 33/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8994 - loss: 0.2880 - val_accuracy: 0.8184 - val_loss: 0.5903\n",
            "Epoch 34/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.8982 - loss: 0.2790 - val_accuracy: 0.8934 - val_loss: 0.4186\n",
            "Epoch 35/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.9014 - loss: 0.2747 - val_accuracy: 0.9250 - val_loss: 0.2491\n",
            "Epoch 36/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9142 - loss: 0.2540 - val_accuracy: 0.8945 - val_loss: 0.3141\n",
            "Epoch 37/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9071 - loss: 0.2630 - val_accuracy: 0.8799 - val_loss: 0.3294\n",
            "Epoch 38/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9103 - loss: 0.2630 - val_accuracy: 0.9143 - val_loss: 0.3250\n",
            "Epoch 39/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9105 - loss: 0.2441 - val_accuracy: 0.9297 - val_loss: 0.2122\n",
            "Epoch 40/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9089 - loss: 0.2609 - val_accuracy: 0.8743 - val_loss: 0.9024\n",
            "Epoch 41/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.9149 - loss: 0.2435 - val_accuracy: 0.8520 - val_loss: 0.5218\n",
            "Epoch 42/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9125 - loss: 0.2612 - val_accuracy: 0.9330 - val_loss: 0.3070\n",
            "Epoch 43/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 253ms/step - accuracy: 0.9158 - loss: 0.2639 - val_accuracy: 0.9416 - val_loss: 0.2393\n",
            "Epoch 44/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9163 - loss: 0.2402 - val_accuracy: 0.9325 - val_loss: 0.1861\n",
            "Epoch 45/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9162 - loss: 0.2368 - val_accuracy: 0.8074 - val_loss: 0.6200\n",
            "Epoch 46/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 254ms/step - accuracy: 0.9154 - loss: 0.2309 - val_accuracy: 0.9435 - val_loss: 0.1962\n",
            "Epoch 47/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9169 - loss: 0.2460 - val_accuracy: 0.9132 - val_loss: 0.2067\n",
            "Epoch 48/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9242 - loss: 0.2568 - val_accuracy: 0.9446 - val_loss: 0.2257\n",
            "Epoch 49/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9211 - loss: 0.2327 - val_accuracy: 0.7983 - val_loss: 0.6763\n",
            "Epoch 50/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9207 - loss: 0.2257 - val_accuracy: 0.8225 - val_loss: 1.0368\n",
            "Epoch 51/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9221 - loss: 0.2397 - val_accuracy: 0.8650 - val_loss: 0.6122\n",
            "Epoch 52/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9191 - loss: 0.2766 - val_accuracy: 0.9350 - val_loss: 0.3245\n",
            "Epoch 53/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9253 - loss: 0.2269 - val_accuracy: 0.9363 - val_loss: 0.2112\n",
            "Epoch 54/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9223 - loss: 0.2325 - val_accuracy: 0.9515 - val_loss: 0.1554\n",
            "Epoch 55/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9214 - loss: 0.2424 - val_accuracy: 0.9226 - val_loss: 0.2928\n",
            "Epoch 56/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9248 - loss: 0.2351 - val_accuracy: 0.9262 - val_loss: 0.2043\n",
            "Epoch 57/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9187 - loss: 0.2461 - val_accuracy: 0.8143 - val_loss: 0.7848\n",
            "Epoch 58/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9314 - loss: 0.2105 - val_accuracy: 0.9611 - val_loss: 0.1348\n",
            "Epoch 59/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9254 - loss: 0.2289 - val_accuracy: 0.9427 - val_loss: 0.1954\n",
            "Epoch 60/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9264 - loss: 0.2355 - val_accuracy: 0.7953 - val_loss: 1.0828\n",
            "Epoch 61/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9277 - loss: 0.2285 - val_accuracy: 0.9474 - val_loss: 0.1886\n",
            "Epoch 62/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9278 - loss: 0.2248 - val_accuracy: 0.9328 - val_loss: 0.2564\n",
            "Epoch 63/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9274 - loss: 0.2183 - val_accuracy: 0.9377 - val_loss: 0.2295\n",
            "Epoch 64/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9306 - loss: 0.2102 - val_accuracy: 0.8303 - val_loss: 0.7967\n",
            "Epoch 65/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9328 - loss: 0.2112 - val_accuracy: 0.6172 - val_loss: 5.9976\n",
            "Epoch 66/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9290 - loss: 0.2319 - val_accuracy: 0.6903 - val_loss: 3.8645\n",
            "Epoch 67/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9259 - loss: 0.2191 - val_accuracy: 0.8495 - val_loss: 0.5535\n",
            "Epoch 68/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9364 - loss: 0.2045 - val_accuracy: 0.7545 - val_loss: 2.3060\n",
            "Epoch 69/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 253ms/step - accuracy: 0.9296 - loss: 0.2106 - val_accuracy: 0.8033 - val_loss: 0.9113\n",
            "Epoch 70/70\n",
            "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 252ms/step - accuracy: 0.9379 - loss: 0.2025 - val_accuracy: 0.9002 - val_loss: 0.3589\n"
          ]
        }
      ],
      "source": [
        "# Initiating model on GPU\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(augmentation) # Adding data augmentation pipeline to the model\n",
        "\n",
        "    # Feature Learning Layers\n",
        "    model.add(Conv2D(32,                  # Number of filters/Kernels\n",
        "                     (3,3),               # Size of kernels (3x3 matrix)\n",
        "                     strides = 1,         # Step size for sliding the kernel across the input (1 pixel at a time).\n",
        "                     padding = 'same',    # 'Same' ensures that the output feature map has the same dimensions as the input by padding zeros around the input.\n",
        "                    input_shape = (400,400,3) # Input image shape\n",
        "                    ))\n",
        "    model.add(Activation('relu'))# Activation function\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(64, (5,5), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(256, (5,5), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(512, (3,3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Flattening tensors\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully-Connected Layers\n",
        "    model.add(Dense(2048))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(2, activation = 'sigmoid')) # Binary classification layer\n",
        "\n",
        "\n",
        "    # Compiling model\n",
        "    model.compile(optimizer = tf.keras.optimizers.RMSprop(0.0001), # 1e-4\n",
        "              loss = 'binary_crossentropy', # Ideal for multiclass tasks\n",
        "              metrics = ['accuracy']) # Evaluation metric\n",
        "    #compile the model\n",
        "    try:\n",
        "      history = model.fit(\n",
        "        train, epochs = 70,\n",
        "        validation_data = testing)\n",
        "    except Exception as e:\n",
        "      print(\"An error occurred:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1OqsqI4l3_F"
      },
      "outputs": [],
      "source": [
        "model.save('drive/MyDrive/Capstone3/safety_gear_detect_V4.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "O-SF0_SBl6hO",
        "outputId": "08a6fe48-5aa2-4b8d-a6f1-d7f1cbaf1b14"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjYklEQVR4nO3deVwU5eMH8M8esMutyCmgIN63YhDeJoZHmmVqp0ep5ZEanf7Kq4suzTILO0xLy9uy9OsRpmWiJt63ogiigKjcl+w+vz9GVjdAWQSGHT7v12tfsLMzO88szPDhuUYlhBAgIiIikola7gIQERFR7cYwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMFJNNm3ahPbt20Ov10OlUiE9PV3uIpVKpVJh1qxZcheDKmj79u1QqVRYvXq13EUhomqkUqkwadIkuYtRYVYdRhYvXgyVSoV9+/bJXZQ7unr1KoYNGwY7OzssWLAAP/74IxwcHGQrz8aNGxk4iCrRl19+CZVKhZCQELmLQmSVtHIXoDb4999/kZWVhXfeeQdhYWFyFwcbN27EggULSg0keXl50Gr5a0FkiWXLlsHf3x979+7F2bNn0bhxY7mLRGRVrLpmxFqkpqYCAOrUqSNvQcpBr9fX+jCSk5MjdxHIipw/fx67du3C3Llz4e7ujmXLlsldpDLxd7tsRUVFKCwslLsYtVatCCMHDhxAv3794OzsDEdHR/Tu3Ru7d+82W+fGjRuYPXs2mjRpAr1ej3r16qFr167YunWraZ3k5GSMHj0avr6+0Ol08Pb2xsMPP4z4+Pgy992zZ0+MHDkSAHDfffdBpVJh1KhRAAB/f3/T9//dpmfPnqbnxf0AVq5ciffeew++vr7Q6/Xo3bs3zp49W2L7PXv2oH///qhbty4cHBzQtm1bfPbZZwCAUaNGYcGCBQCkNsbiR7HS+oyU5/MrbjL7559/EBERAXd3dzg4OOCRRx7BlStXyvx8brdt2zZ069YNDg4OqFOnDh5++GGcOHHC9Prq1auhUqmwY8eOEtsuXLgQKpUKR48eNS07efIkHnvsMbi6ukKv16NTp05Yv359qeXesWMHJkyYAA8PD/j6+t6xnAUFBZg5cyYaN24MnU4HPz8/vPbaaygoKDBbr7gNd9myZWjWrBn0ej2CgoLw119/lXjP8nzGAJCeno6XXnoJ/v7+0Ol08PX1xYgRI5CWlma2ntFovOvvypkzZzBkyBB4eXlBr9fD19cXjz/+ODIyMu54/GRu2bJlqFu3LgYMGIDHHnuszDBSnp9dfn4+Zs2ahaZNm0Kv18Pb2xuPPvoo4uLiANy6Fmzfvt3svePj46FSqbB48WLTslGjRsHR0RFxcXHo378/nJyc8NRTTwEA/v77bwwdOhQNGjQw/Q6/9NJLyMvLK1HukydPYtiwYXB3d4ednR2aNWuGN998EwDw559/QqVSYd26dSW2++mnn6BSqRATE3PHz+/cuXMYOnQoXF1dYW9vj/vvvx8bNmwwvZ6SkgKtVovZs2eX2PbUqVNQqVT44osvzD7nqVOnws/PDzqdDo0bN8aHH34Io9FY4vP65JNPMG/ePAQGBkKn0+H48eN3LOvSpUsRFBQEOzs7uLq64vHHH0diYqLZOj179kTr1q0RGxuLzp07w87ODgEBAYiKiirxfqmpqXjuuefg6ekJvV6Pdu3aYcmSJSXWMxqN+Oyzz9CmTRvo9Xq4u7ujb9++pXZR+OWXX9C6dWvodDq0atUKmzZtMns9KysLU6dONf0eenh4oE+fPti/f/8dj72qKf5f4GPHjqFbt25wdnbGa6+9BhsbGyxcuBA9e/bEjh07TG28s2bNQmRkJMaMGYPg4GBkZmZi37592L9/P/r06QMAGDJkCI4dO4YXX3wR/v7+SE1NxdatW5GQkAB/f/9S9//mm2+iWbNm+Prrr/H2228jICAAgYGBFTqWDz74AGq1Gq+88goyMjLw0Ucf4amnnsKePXtM62zduhUPPfQQvL29MWXKFHh5eeHEiRP4/fffMWXKFDz//PO4dOkStm7dih9//LHSPr9iL774IurWrYuZM2ciPj4e8+bNw6RJk7BixYo77uePP/5Av3790KhRI8yaNQt5eXmYP38+unTpgv3798Pf3x8DBgyAo6MjVq5ciR49ephtv2LFCrRq1QqtW7c2lbtLly7w8fHBG2+8AQcHB6xcuRKDBw/GmjVr8Mgjj5htP2HCBLi7u2PGjBl3/O/RaDRi0KBB2LlzJ8aNG4cWLVrgyJEj+PTTT3H69Gn88ssvZuvv2LEDK1aswOTJk6HT6fDll1+ib9++2Lt3r1lZy/MZZ2dno1u3bjhx4gSeffZZdOzYEWlpaVi/fj0uXrwINzc3037v9rtSWFiI8PBwFBQU4MUXX4SXlxeSkpLw+++/Iz09HS4uLnf8edEty5Ytw6OPPgpbW1s88cQT+Oqrr/Dvv//ivvvuM61Tnp+dwWDAQw89hOjoaDz++OOYMmUKsrKysHXrVhw9erRC142ioiKEh4eja9eu+OSTT2Bvbw8AWLVqFXJzczF+/HjUq1cPe/fuxfz583Hx4kWsWrXKtP3hw4fRrVs32NjYYNy4cfD390dcXBx+++03vPfee+jZsyf8/PywbNmyEufUsmXLEBgYiNDQ0DLLl5KSgs6dOyM3NxeTJ09GvXr1sGTJEgwaNAirV6/GI488Ak9PT/To0QMrV67EzJkzzbZfsWIFNBoNhg4dCgDIzc1Fjx49kJSUhOeffx4NGjTArl27MG3aNFy+fBnz5s0z2/77779Hfn4+xo0bB51OB1dX1zLL+t5772H69OkYNmwYxowZgytXrmD+/Pno3r07Dhw4YFbzff36dfTv3x/Dhg3DE088gZUrV2L8+PGwtbXFs88+C0BqEu/ZsyfOnj2LSZMmISAgAKtWrcKoUaOQnp6OKVOmmN7vueeew+LFi9GvXz+MGTMGRUVF+Pvvv7F792506tTJtN7OnTuxdu1aTJgwAU5OTvj8888xZMgQJCQkoF69egCAF154AatXr8akSZPQsmVLXL16FTt37sSJEyfQsWPHMo+/ygkr9v333wsA4t9//y1zncGDBwtbW1sRFxdnWnbp0iXh5OQkunfvblrWrl07MWDAgDLf5/r16wKA+PjjjyutnA0bNhQjR44ssX6PHj1Ejx49TM///PNPAUC0aNFCFBQUmJZ/9tlnAoA4cuSIEEKIoqIiERAQIBo2bCiuX79u9p5Go9H0/cSJE0VZP3oAYubMmabn5f38io8xLCzMbF8vvfSS0Gg0Ij09vdT9FWvfvr3w8PAQV69eNS07dOiQUKvVYsSIEaZlTzzxhPDw8BBFRUWmZZcvXxZqtVq8/fbbpmW9e/cWbdq0Efn5+WafQefOnUWTJk1KlLtr165m71mWH3/8UajVavH333+bLY+KihIAxD///GNaBkAAEPv27TMtu3DhgtDr9eKRRx4xLSvvZzxjxgwBQKxdu7ZEuYo/8/L+rhw4cEAAEKtWrbrrMVPZ9u3bJwCIrVu3CiGkn4Ovr6+YMmWK2Xrl+dktWrRIABBz584tc53in++ff/5p9vr58+cFAPH999+blo0cOVIAEG+88UaJ98vNzS2xLDIyUqhUKnHhwgXTsu7duwsnJyezZbeXRwghpk2bJnQ6ndk5npqaKrRardm1pDRTp04VAMzOp6ysLBEQECD8/f2FwWAQQgixcOFCs9/fYi1bthQPPPCA6fk777wjHBwcxOnTp83We+ONN4RGoxEJCQlCiFufl7Ozs0hNTb1jGYUQIj4+Xmg0GvHee++ZLT9y5IjQarVmy3v06CEAiDlz5piWFRQUmK5xhYWFQggh5s2bJwCIpUuXmtYrLCwUoaGhwtHRUWRmZgohhNi2bZsAICZPnlyiXLf/HAAIW1tbcfbsWdOyQ4cOCQBi/vz5pmUuLi5i4sSJdz3m6qboZhqDwYAtW7Zg8ODBaNSokWm5t7c3nnzySezcuROZmZkApP4cx44dw5kzZ0p9Lzs7O9ja2mL79u24fv16tZT/v0aPHg1bW1vT827dugGQqjkBqar//PnzmDp1aon+Kbc3xZSXJZ9fsXHjxpntq1u3bjAYDLhw4UKZ+7l8+TIOHjyIUaNGmf1n0rZtW/Tp0wcbN240LRs+fDhSU1PNqqlXr14No9GI4cOHAwCuXbuGbdu2YdiwYcjKykJaWhrS0tJw9epVhIeH48yZM0hKSjIrw9ixY6HRaO76maxatQotWrRA8+bNTe+blpaGBx54AIBUbX270NBQBAUFmZ43aNAADz/8MDZv3gyDwWDRZ7xmzRq0a9euxH+gQMmf791+V4prPjZv3ozc3Ny7HjeVbtmyZfD09ESvXr0ASD+H4cOHY/ny5TAYDKb1yvOzW7NmDdzc3PDiiy+WuU5FjB8/vsQyOzs70/c5OTlIS0tD586dIYTAgQMHAABXrlzBX3/9hWeffRYNGjQoszwjRoxAQUGB2XDyFStWoKioCE8//fQdy7Zx40YEBweja9eupmWOjo4YN24c4uPjTc0mjz76KLRarVkN69GjR3H8+HHTeQ9I52e3bt1Qt25ds/MzLCwMBoOhRBPpkCFD4O7ufscyAsDatWthNBoxbNgws/f18vJCkyZNSpz3Wq0Wzz//vOm5ra0tnn/+eaSmpiI2NtZ07F5eXnjiiSdM69nY2GDy5MnIzs42NUevWbMGKpWqRK0QUPL3IiwszKwGrW3btnB2djad94D0t27Pnj24dOnSXY+7Oik6jFy5cgW5ublo1qxZiddatGgBo9Foau97++23kZ6ejqZNm6JNmzZ49dVXcfjwYdP6Op0OH374If73v//B09MT3bt3x0cffYTk5ORqO57/XhDq1q0LAKZwVNyuXFz9f68s+fzKW8bSFAeVsvaTlpZmajrp27cvXFxczC5KK1asQPv27dG0aVMAwNmzZyGEwPTp0+Hu7m72KD6hizsVFwsICCizfLc7c+YMjh07VuJ9i/f93/dt0qRJifdo2rQpcnNzceXKFYs+47i4uHL/bO/2cwgICEBERAS+/fZbuLm5ITw8HAsWLGB/EQsYDAYsX74cvXr1wvnz53H27FmcPXsWISEhSElJQXR0tGnd8vzs4uLi0KxZs0rtQK7VakvtA5WQkGAK/46OjnB3dzc1fRb/DhT/AbtbuZs3b4777rvPrK/MsmXLcP/99991VNGFCxfK/N0vfh0A3Nzc0Lt3b6xcudK0zooVK6DVavHoo4+alp05cwabNm0qcX4Wj2K8l/NeCIEmTZqUeO8TJ06UeN/69euXmL6h+BpR3MfwwoULaNKkCdRq8z/D/z32uLg41K9f/45NSMX+e94D0rl/+/X3o48+wtGjR+Hn54fg4GDMmjXLLKzIRfF9Rsqre/fuiIuLw6+//ootW7bg22+/xaeffoqoqCiMGTMGADB16lQMHDgQv/zyCzZv3ozp06cjMjIS27ZtQ4cOHSzeZ1n/7RgMhlL/Sy/rP3chhMX7ripVXUadTofBgwdj3bp1+PLLL5GSkoJ//vkH77//vmmd4o5qr7zyCsLDw0t9n/9eJG//T/FOjEYj2rRpg7lz55b6up+fX7nep6qV5+cwZ84cjBo1yvQ7P3nyZERGRmL37t137cRLUofry5cvY/ny5Vi+fHmJ15ctW4YHH3ywUvd5p2tGaXQ6XYk/dgaDAX369MG1a9fw+uuvo3nz5nBwcEBSUhJGjRpl1tGzvEaMGIEpU6bg4sWLKCgowO7du806lVaGxx9/HKNHj8bBgwfRvn17rFy5Er179zbrK2U0GtGnTx+89tprpb5HcSAoZsl5r1Kp8L///a/Uc8vR0dGCI6k65Tnvhw0bhm7dumHdunXYsmULPv74Y3z44YdYu3Yt+vXrV11FLUHRYcTd3R329vY4depUiddOnjwJtVpt9sfD1dUVo0ePxujRo5GdnY3u3btj1qxZpjACAIGBgXj55Zfx8ssv48yZM2jfvj3mzJmDpUuXWly+unXrljoT64ULF8yq7MuruHru6NGjd5zPpLxVvpZ+fhXVsGFDAChzP25ubmb/ZQwfPhxLlixBdHQ0Tpw4ASGEWVVt8WdnY2NT6fO6BAYG4tChQ+jdu3e5PsfSmv1Onz4Ne3t7U/VweT/jwMBAs9FClaFNmzZo06YN3nrrLezatQtdunRBVFQU3n333UrdjxItW7YMHh4eptFpt1u7di3WrVuHqKgo2NnZletnFxgYiD179uDGjRuwsbEpdZ3iGq7/Xjfu1Az6X0eOHMHp06exZMkSjBgxwrT89pGDwK3zqDy/c48//jgiIiLw888/Iy8vDzY2NmbnZFkaNmxY5u9+8evFBg8ejOeff95UK3r69GlMmzbNbLvAwEBkZ2dXyXkvhEBAQECJQFOaS5cuIScnx+y6dfr0aQAwDXZo2LAhDh8+DKPRaBYY/3vsgYGB2Lx5M65du1au2pHy8Pb2xoQJEzBhwgSkpqaiY8eOeO+992QNI4puptFoNHjwwQfx66+/mg2/TUlJwU8//YSuXbvC2dkZgDRL6u0cHR3RuHFj03DN3Nxc5Ofnm60TGBgIJyenEkM6yyswMBC7d+82G9v++++/l2j6KK+OHTsiICAA8+bNK3Gxuj0ZF58gd5uS3pLP7154e3ujffv2WLJkiVmZjh49ii1btqB///5m64eFhcHV1RUrVqzAihUrEBwcbFbd6uHhgZ49e2LhwoW4fPlyif2Vd6hxaYYNG4akpCR88803JV7Ly8srMRInJibGbMhcYmIifv31Vzz44IPQaDQWfcZDhgzBoUOHSh1GaWnNU2ZmJoqKisyWtWnTBmq1usK/z7VJXl4e1q5di4ceegiPPfZYicekSZOQlZVlGkpenp/dkCFDkJaWVmqNQvE6DRs2hEajKdH34csvvyx32Yv/e779d0YIYRr+X8zd3R3du3fHokWLkJCQUGp5irm5uaFfv35YunQpli1bhr59+5rVWJSlf//+2Lt3r9nw35ycHHz99dfw9/dHy5YtTcvr1KmD8PBwrFy5EsuXL4etrS0GDx5s9n7Dhg1DTEwMNm/eXGJf6enpJX7ny+vRRx+FRqPB7NmzSxy7EKLE34+ioiIsXLjQ9LywsBALFy6Eu7u7qQ9Z//79kZycbNbkXFRUhPnz58PR0dHUbDZkyBAIIUod2mzpeW8wGEo0xXp4eKB+/fqyn/eKqBlZtGhRibHUADBlyhS8++672Lp1K7p27YoJEyZAq9Vi4cKFKCgowEcffWRat2XLlujZsyeCgoLg6uqKffv2mYY/AVKq7d27N4YNG4aWLVtCq9Vi3bp1SElJweOPP16hco8ZMwarV69G3759MWzYMMTFxWHp0qUVHvqrVqvx1VdfYeDAgWjfvj1Gjx4Nb29vnDx5EseOHTOdoMUnw+TJkxEeHg6NRlPmMZT387tXH3/8Mfr164fQ0FA899xzpqG9Li4uJeY9sbGxwaOPPorly5cjJycHn3zySYn3W7BgAbp27Yo2bdpg7NixaNSoEVJSUhATE4OLFy/i0KFDFSrnM888g5UrV+KFF17An3/+iS5dusBgMODkyZNYuXIlNm/ebDbUrnXr1ggPDzcb2gvA7MJS3s/41VdfxerVqzF06FA8++yzCAoKwrVr17B+/XpERUWhXbt25T6Obdu2YdKkSRg6dCiaNm2KoqIi/Pjjj9BoNBgyZEiFPpvaZP369cjKysKgQYNKff3+++83TYA2fPjwcv3sRowYgR9++AERERHYu3cvunXrhpycHPzxxx+YMGECHn74Ybi4uGDo0KGYP38+VCoVAgMD8fvvv5fos3AnzZs3R2BgIF555RUkJSXB2dkZa9asKbVf1+eff46uXbuiY8eOGDduHAICAhAfH48NGzbg4MGDZuuOGDECjz32GADgnXfeKVdZ3njjDfz888/o168fJk+eDFdXVyxZsgTnz5/HmjVrSjQxDR8+HE8//TS+/PJLhIeHl+io/+qrr2L9+vV46KGHMGrUKAQFBSEnJwdHjhzB6tWrER8fX66Q9F+BgYF49913MW3aNMTHx2Pw4MFwcnLC+fPnsW7dOowbNw6vvPKKaf369evjww8/RHx8PJo2bYoVK1bg4MGD+Prrr021XuPGjcPChQsxatQoxMbGwt/fH6tXr8Y///yDefPmwcnJCQDQq1cvPPPMM/j8889x5swZ9O3bF0ajEX///Td69epl0f1osrKy4Ovri8ceewzt2rWDo6Mj/vjjD/z777+YM2eOxZ9LparewTuVq3hYZlmPxMREIYQQ+/fvF+Hh4cLR0VHY29uLXr16iV27dpm917vvviuCg4NFnTp1hJ2dnWjevLl47733TMOw0tLSxMSJE0Xz5s2Fg4ODcHFxESEhIWLlypXlLmdpQ5DnzJkjfHx8hE6nE126dBH79u0rc2jvf4dhljacTwghdu7cKfr06SOcnJyEg4ODaNu2rdnQrqKiIvHiiy8Kd3d3oVKpzIb54j9De8v7+ZV1jGUNRSzNH3/8Ibp06SLs7OyEs7OzGDhwoDh+/Hip627dulUAECqVyvRz/q+4uDgxYsQI4eXlJWxsbISPj4946KGHxOrVq+9a7jspLCwUH374oWjVqpXQ6XSibt26IigoSMyePVtkZGSY1gMgJk6cKJYuXSqaNGkidDqd6NChQ6mfRXk+YyGEuHr1qpg0aZLw8fERtra2wtfXV4wcOVKkpaUJIcr/u3Lu3Dnx7LPPisDAQKHX64Wrq6vo1auX+OOPP8r9OdRmAwcOFHq9XuTk5JS5zqhRo4SNjY3pZ3O3n50Q0pDbN998UwQEBAgbGxvh5eUlHnvsMbNh31euXBFDhgwR9vb2om7duuL5558XR48eLXVor4ODQ6llO378uAgLCxOOjo7Czc1NjB071jQM9L/Xk6NHj4pHHnlE1KlTR+j1etGsWTMxffr0Eu9ZUFAg6tatK1xcXEReXl55PkYhhHSePvbYY6b3Dw4OFr///nup62ZmZgo7O7sSQ2Jvl5WVJaZNmyYaN24sbG1thZubm+jcubP45JNPTNfz4vPB0qka1qxZI7p27SocHByEg4ODaN68uZg4caI4deqUaZ0ePXqIVq1aiX379onQ0FCh1+tFw4YNxRdffFHi/VJSUsTo0aOFm5ubsLW1FW3atCnx+QshXbM//vhj0bx5c2Frayvc3d1Fv379RGxsrGmd4uvNf90+hURBQYF49dVXRbt27Ux/H9q1aye+/PJLiz6HqqASogb1fiRSEJVKhYkTJ1Z6Rz6imqioqAj169fHwIED8d1338ldHNn07NkTaWlpld6/S+kU3WeEiIiqxy+//IIrV66YdYolKi9F9BkhIiJ57NmzB4cPH8Y777yDDh06lLhVA1F5sGaEiIgq7KuvvsL48ePh4eGBH374Qe7ikJVinxEiIiKSFWtGiIiISFYMI0RERCQrq+jAajQacenSJTg5Od3T3SuJqGKEEMjKykL9+vVLTERVU/G6QSS/8l47rCKMXLp0qcbcgIyoNktMTLSam+jxukFUc9zt2mEVYaR4WtzExMRKuRcKEVkmMzMTfn5+pnPRGvC6QSS/8l47rCKMFFexOjs786JCJCNrau7gdYOo5rjbtcM6Gn+JiIhIsRhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMEJERESyYhghIiIiWTGMEBERkawYRoiIiEhWDCNEREQkK4YRIiIikpViwkhOQRFm/3YMM389CiGE3MUhIiKyfnnJwH//pmacBKJ7AzkXKm03igkjhUVGfP9PPJbEXICRWYSIiOjeHJkNrPMGttwPXPkHEEbg1OfApg5AyjYgdmql7Upbae8kM7X61u2Ji4xGaNQaGUtDRERkxRLXAUdmSd9f3Qts7Qo4Ngayz0rLvB4EOn1RabtTTBjR3BZGjEYZC0JERFTTFeUClzYCunqAayfAxunWaxkngJgR0veBY6Wv576TgojGDujwMdBkAqBSlXzfClJMGNHeFkYM7DNCRES1jRDlCwgp24E9Y4DsOOm5Sg04twScGgP2vsClTUBRNuDRA7hvAaC2AZpOAhLXAP5PAs7NKr3oigkj6tt+AAYDwwgRESlIXjJg6wpobEt/PXUnEPMMUL+f1HyiKqVLaOF14OAbwNmvped6L0BtC+QmABlHpUcxez+g60opiABA3bbSo4ooJoxoWDNCRERKdG0/sLUboHMDHtgKODc1fz1tL7C9P1CUBZz5CtA6SE0pxYwGIO5b4PCbQMFVaVnj54H2HwK2LkDeZeBaLJCTAOQlSes0fRHQe1TbISomjNyWRWDgcBoiIlICIYADrwCGXKkGY2tXoNdmwLWD9Pr1g8Cf4VIQcW4BZJ4ATnwC2PkAjUYDCauA018A6Yek9V1aAp0WAJ49b+3Dzhvweai6j8yMYsKISqWCRq2CwSgYRoiISBkubQRS/gTUOqmvRvphILon0GC41KH06r9S/w63zlJIObNAaorZHwEcmgYY8qX3sXEB2r4NNBl/q+mlBlHMPCMAoLnZb4TNNEREVCWuHQAS15acCOx2hgJptIqlbmQCe8YCB6cBN7IBYxFw8DXptWZTgLC/AI/u0npx30ghpSgbqBcM9NwI2DgCLV4DmkwEIKQg4tJSao4ZeAZoNrlGBhFAQTUjwM1+IwbAyJoRIiKqbLlJUjOJIVcKBx0/LTl6JTseiH5A6nvh1QfwGwLoXIHUv4G0XVINReBzgO/D5sGg4BrwZ1/g2r/S8ws/A/UHABnHpeG3raZJ/Tt6bgJOzwduZABOzaTaEtcgQH3zz7lKBQR9Bng9ADg0BOp2rNQhuFVFeWEEQBHDCBERVbaDb0hBBABOfSbNSBr02a0/9rkXpSCSc156fmmD9Pivy5ukfhoNn5BqOpyaAv8MB9KPSMFD6yhNtX7mS2n9VtMB2zrS91o7oOVrdy6nWgP4PXrPh1udFBVGijuxss8IERFViKGw9OGzV2KA+KUAVECLl4ETc6QaioKrgN8jgH0DaWhtznnAsREQsghI3QFc/BUw5gNuXQD3rkDWKWlkS95l4ORc6VHMzhvotVWq0Tj0pvT+Li2kfh4KZ3Gfkb/++gsDBw5E/fr1oVKp8Msvv9x1m+3bt6Njx47Q6XRo3LgxFi9eXIGi3p1WIx2OkX1GiIjIEoZ84M9+0r1Yruwyf00Ygdgp0veNRkvDZkO+BaACLvwE7BwKbAkBsk5LoaT3NsCzB9BmBtAvFhhwDAj5Gmg0Amj3HvBwItB1FdB4nDQCBgAc/KU+IXVaSX0/On0GDL4IPBhT9twiCmJxGMnJyUG7du2wYMGCcq1//vx5DBgwAL169cLBgwcxdepUjBkzBps3b7a4sHdTPPFZESc9IyKi8hJGIGaU1HxSeA34e4jUP6TY+R+kvhxaJylMAEDgs1Kn0UajAdf7AI29VKPRO1r6eicaW6DBY0DwQuCh48Bj14CHTkgzoN7Ovj5g41yph1pTWdxM069fP/Tr16/c60dFRSEgIABz5swBALRo0QI7d+7Ep59+ivDw8FK3KSgoQEFBgel5ZmZmufZ1s2KENSNERFR+h/4PSFghdSi19wOyzwF/PQL0/gM4+Slw7GYAaT0dsPO6tV39vtIDkAINVBXrLGpb954PwdpVeZ+RmJgYhIWFmS0LDw/H1KlTy9wmMjISs2fPtnhfWrWURthnhIiIypTyJ3BuMWDIA25kSTUiABD8LeDRFdh0n1QTss5XmkwMkDqENptS9nuWNv06lVuVf3rJycnw9PQ0W+bp6YnMzEzk5eWVus20adOQkZFheiQmJpZrXzezCEfTEBERkJMIxC2SAkexxLXAtgelppeEVbeCSJu3pT4djo2ke7KoNFIQ0bkDXVYAXVfXir4bcqmRo2l0Oh10Op3F2xVPesZmGiKiWq4wHfijhzS65fB0oMMcaS6Ofx4HhAHwHQx49paaZpwaA54P3NrWqzfQbR1wdQ/QbCqgd5PpIGqPKg8jXl5eSElJMVuWkpICZ2dn2NnZVeq+iucZYTMNEVEtJoQ0k2nxfB95l4BdT9x63f9p4P7F0nwcZfEdKD2oWlR5M01oaCiio6PNlm3duhWhoaGVvi+GESKiWsRQUPq07Ge+AhJXS7UeYX9JTTAavfSa/zN3DyJU7SyuGcnOzsbZs2dNz8+fP4+DBw/C1dUVDRo0wLRp05CUlIQffvgBAPDCCy/giy++wGuvvYZnn30W27Ztw8qVK7FhQymz0t2j4qG9DCNERAqWfR6InQokrZeG2zoGSMNpdfUArTNwNkpar/2HgEc36dFoBHD9MFC/P4NIDWRxGNm3bx969epleh4REQEAGDlyJBYvXozLly8jISHB9HpAQAA2bNiAl156CZ999hl8fX3x7bffljms916YakbYZ4SISBkKrgHnfwQ0OmkIbOZJ4PgHt+5GW5Ql3ck2/bD5dj6DpP4exRwa3n3+D5KNxWGkZ8+eEHf4Y1/a7Ko9e/bEgQMHLN2VxbTFYYSTnhER1Rw5F4Bj7wNeYYDfY+Wfi8NokCYgS91e8jWPnkDQp4BaJ80LkpsodVotvC4Ns235ulXcII4kNXI0TUWpWTNCRFSz5CZJN4/LPgec/VpqJum0AHD0v/u2Jz6UgojWQboDbuF1aXKxJi9IN5krDhsuLaryCKgaKGqWFtPQXvYZIapxFixYAH9/f+j1eoSEhGDv3r1lrnvjxg28/fbbCAwMhF6vR7t27bBp06ZqLC1VirwUYFtvKYjYeQNqW+DSRmBDK+DfiUDqzpszl5YibTdweIb0facvgO7rgLDtQJ+/AP8nWeuhMMoKIzdrRjjpGVHNsmLFCkRERGDmzJnYv38/2rVrh/DwcKSmppa6/ltvvYWFCxdi/vz5OH78OF544QU88sgj1dLcS5UkNwn4sw+QeUq6edyDMUC/Q4BHD8CQC5z5EvijG/CrP5Cwxnzbwgzgnyel+UAaPg4EjJTlEKj6KDKMcNIzoppl7ty5GDt2LEaPHo2WLVsiKioK9vb2WLRoUanr//jjj/i///s/9O/fH40aNcL48ePRv39/0z2uqIaL/xnY0BpIPyLViBTfPM6lOdD7T6DXZilg2DhLfT12DgVO37z5auYpYGtXaY4QB3/gvijWgtQCigwjHNpLVHMUFhYiNjbW7B5VarUaYWFhiImJKXWbgoIC6PV6s2V2dnbYuXNnmfspKChAZmam2YOqUP4VqYPp7YpygH+eAHY9CdxIl+5mG/aX+d1oVSrA+0EgdDHwaArQZDwAAeybBPzzFLCpE5BxFNB7At1WA7Yu1XhQJBeGESKqUmlpaTAYDKXeoyo5ObnUbcLDwzF37lycOXMGRqMRW7duxdq1a3H58uUy9xMZGQkXFxfTw8/Pr1KPg27KTQJiRgFrPYE/ut+674swArueBi4sl+7r0mYW8OA/5kHkvzR6qTNrm5s3Rr3wE1CULY2U6XcQcA2q2mOhGkNZYYSTnhEpwmeffYYmTZqgefPmsLW1xaRJkzB69Gio1WVfsip6g026TVEOkPQ7cOB14NwS85qPohzg8Czgt6bA+SUABJC2C/jrYWnOj0NvAhd/kTqpPhANtJkpzYB6NyoV0GYGEPw1YO8LtJ4OPLAVsPOqmmOkGolDe4moSrm5uUGj0ZR6jyovr9L/4Li7u+OXX35Bfn4+rl69ivr16+ONN95Ao0aNytxPRW+wSZCCxu7RwMVfAWPhreWnF0gjWTKOAYffBPJu1ky5dwECxwD7XgRS/gQ2B0v9QwAgZBHg2cPyMjQeKz2oVlJUzUjxpGcc2ktUc9ja2iIoKMjsHlVGoxHR0dF3vUeVXq+Hj48PioqKsGbNGjz88MNVXdzaad+LQMIqKYg4+Es3krNxBq79C2wJAfY8KwURhwCg60og7G+g0Sigx+9SU0txEGn1FhDwlJxHQlZKkTUjHNpLVLNERERg5MiR6NSpE4KDgzFv3jzk5ORg9OjRAIARI0bAx8cHkZGRAIA9e/YgKSkJ7du3R1JSEmbNmgWj0YjXXntNzsOwXsW1xaWNSjm/DDj3vTRraY8NgHe4tF7eZeDAa0D8UimYtJ4ONH1Rmpa9mGcPoNtaIOYZwOdhoO3s6jkeUhxFhRH2GSGqmYYPH44rV65gxowZSE5ORvv27bFp0yZTp9aEhASz/iD5+fl46623cO7cOTg6OqJ///748ccfUadOHZmOwEoZCoG4b6V7uejqAd3WAI63NXVlnQX+fUH6vtV0oH7fW6/ZeQOdfwRavwXoPaT7wpSmfj/g0VQpzBBVkKLCiJbzjBDVWJMmTcKkSZNKfW379u1mz3v06IHjx49XQ6kULP5n4ND/ATnx0vPcRGBzCNBtndTnI2UbsP+lm6NXukuhozTOze6+LwYRukeKCiNspiGiWs9QIPUBiftGeq73Alq8Kg2bvRYrTc9u3wDIPiu9busKdF4GqBX154CsjKLiLO9NQ0S1Wu4lILrXzSCiAlrPBAbFAS0ipMnH/IZInVSzzwJaJ6DJBCB8rzSklkhGiorCGk1xnxGZC0JEVN0S10n9P/JTAZs6QJefpP4cxbT20kiYuG8BqIGGwwEbJ7lKS2RGWWHE1IGVaYSIaomCq8C+yVIzDADUaSONcClt5lOVGmg8rnrLR1QOygojnPSMiGqTwnRpwrHsc1LQaPG6NPOphpO/kXVRZhhhxQgRKZ0QwL/jpSBi3wDougpwC5a7VEQVoqwOrGo20xCRAhkNQME1oCjv1rL4ZbduStd1JYMIWTVF1YyoVawZISIrJgSQuAa4uB7IuwjkXgTyU4AbmdLrGj3g9xjgOwj4d4K0rM0swC1EtiITVQZFhRFOekZEVqvgKrD3BSBxddnrGPKl6dnjl0rP3bsCLadVT/mIqpCiwsitSc9YNUJEVuTyFiBmJJCfDKi0QLPJQN2OgL2PNGmZzlUarnv9oDQ098LP0lDd0B8BtUbu0hPdM0WFEQ2baYjImggBnJwj3ZAOAnBuId0PxjWo9PXdgqVHp88BYZQCCZECKCqMaDWcgZWIrIQhH9gzDoj/UXoeOBYI+gzQ2t19W42+astGVM0UFUaKO7Dy3jREVKMZDcCOh4HkLdJomI7zgKYTgZvXMKLaRlFhRHNzoDI7sBJRjXb8AymIaOyBHusBr95yl4hIVgqbZ0Q6HANrRoioprryD3BkpvT9fV8yiBBBaTUjN2s4GUaIqMY4+i4Qtwjw6A549wUOvg4IA+D/NBAwQu7SEdUIygojphlYGUaIqAa4flCqBRFG4Px54PwSabljY6lWhH1EiAAoLozcbKZhnxEikpsQwL5JUhDx7isN2036DbhxHei6HLBxkruERDWGwsKI9JU1I0RU7W5kAVf3Au7dAI2tdO+YK/9InVRDvgHsfYGguXKXkqhGUlQYuXVvGoYRIqpGwghsHwBc+VsKHc1eAk58LL3W+i1pGRGVSVFhxDTpGZtpiKg6xX0nBRFAurndgZel7x0bA80j5CsXkZVQ1NBe06RnBoYRIqomeSk3p3MH0P4D4L4owCEAUNtInVQ1OnnLR2QFFFUzYhpNw5oRIqou+yOAG+nSje2avwyotUDgGKAoG7B1kbt0RFZBUTUjWjXvTUNE1ejyFuDCT4BKDYR8LQURQLqTLoMIUbkpKoyYOrCyZoSIqtqNTGDPWOn7JpPKvtMuEd2VosIIJz0jomqzPwLITZD6h7R7V+7SEFk1RYURNcMIEVWHpA3SCBqogNDFnMCM6B4pKoxoGUaIqKoVXAX2jJG+b/6SdM8ZIronigojGk56RkRV7cArQH4y4NwcaMvmGaLKoKgwoubQXiKqStdigXOLpe/v/x7Q2slaHCKlUFQY4dBeIqoyQgD7b86s6v8U4Ha/vOUhUhBFhZHimpEihhEiqmwXfwFSdwAaPdDufblLQ6QoigojxX1GWDNCRJXKUAgceFX6vvnLgEMDectDpDDKCiPsM0JEVeH0fCA7DtB7AS1fl7s0RIqjzDDCmhEiqiw5icCRmdL37d7lnCJEVYBhhIjoTmJfBIpyAPcuQKPRcpeGSJEYRoiIypL4C3DxV0ClBe5bKN0Qj4gqnaLOLE56RkSV5kYWsG+S9H3L14A6reQtD5GCKSuMsAMrEVWWk58CeUmAYyDQ6i25S0OkaIoMI0ajzAUhIuuXul362vJ1zrRKVMUUGUaKmEaI6F4IozT1O8CZVomqgaLCiLp40jMBCDbVEFFFZZ0BbmQCGjvAuYXcpSFSPEWFkeJ70wBSICEiqpCr/0pf63YA1Fp5y0JUCygqjKhvCyNsqiGiCru2T/pa7z55y0FUSygqjGhurxlhFiGiiioOI66d5C0HUS2hqDByezMNh/cSUYUYi4Br+6XvWTNCVC0UFUaKO7ACgMHAMEJEFZB5AjDkAVonwKmJ3KUhqhUUFUY0rBkhontV3HnVNYjTvxNVE0WdabdlEU4JT0QVw86rRNVOUWFEpVLxZnlEdG+usvMqUXVTVBgBbrtZHptpiMhShkIg/ZD0fT2GEaLqorwwYro/DcMIEVko4whgLARsXQGHALlLQ1RrKDaMFDGMEJGlTJ1XOwG3jc4joqqluDBS3ImVfUaIyGKZp6SvddvKWw6iWkZxYUSrkQ7JyD4jRGSpohzpq42LvOUgqmUUF0aKJz4r4qRnRGQpQ670VWMvbzmIahnFhZGbFSOsGSEiyxXdDCNahhGi6lShMLJgwQL4+/tDr9cjJCQEe/fuveP68+bNQ7NmzWBnZwc/Pz+89NJLyM/Pr1CB70arlg6JfUaIyGKGPOkra0aIqpXFYWTFihWIiIjAzJkzsX//frRr1w7h4eFITU0tdf2ffvoJb7zxBmbOnIkTJ07gu+++w4oVK/B///d/91z40tzMIpxnhIgsV9xMo7WTtxxEtYzFYWTu3LkYO3YsRo8ejZYtWyIqKgr29vZYtGhRqevv2rULXbp0wZNPPgl/f388+OCDeOKJJ+5am1JRpknPWDNCRJYqYp8RIjlYFEYKCwsRGxuLsLCwW2+gViMsLAwxMTGlbtO5c2fExsaawse5c+ewceNG9O/fv8z9FBQUIDMz0+xRXpwOnogqzMA+I0Ry0FqyclpaGgwGAzw9Pc2We3p64uTJk6Vu8+STTyItLQ1du3aFEAJFRUV44YUX7thMExkZidmzZ1tSNBPOwEpEFVZU3GeEzTRE1anKR9Ns374d77//Pr788kvs378fa9euxYYNG/DOO++Uuc20adOQkZFheiQmJpZ7f6ahvQwjRGQpDu0lkoVFNSNubm7QaDRISUkxW56SkgIvL69St5k+fTqeeeYZjBkzBgDQpk0b5OTkYNy4cXjzzTehVpfMQzqdDjqdzpKimWg1vFEeEVUQh/YSycKimhFbW1sEBQUhOjratMxoNCI6OhqhoaGlbpObm1sicGg0GgCAqILAUNyBlc00RGQx1owQycKimhEAiIiIwMiRI9GpUycEBwdj3rx5yMnJwejRowEAI0aMgI+PDyIjIwEAAwcOxNy5c9GhQweEhITg7NmzmD59OgYOHGgKJZVJzRvlEVFFGG8AwiB9z6G9RNXK4j4jw4cPxyeffIIZM2agffv2OHjwIDZt2mTq1JqQkIDLly+b1n/rrbfw8ssv46233kLLli3x3HPPITw8HAsXLqy8o7gNa0aIaqaaPFkigFtNNABrRoiqmcU1IwAwadIkTJo0qdTXtm/fbr4DrRYzZ87EzJkzK7Iri5mG9rLPCFGNUTxZYlRUFEJCQjBv3jyEh4fj1KlT8PDwKLF+8WSJixYtQufOnXH69GmMGjUKKpUKc+fOrZpCFjfRqNSA2rZq9kFEpVLgvWk4zwhRTVPTJ0sEYD7h2c0aViKqHgwjRFSlrGGyRAC33ZeG/UWIqluFmmlqMoYRoprFGiZLBMBhvUQyUl7NCO9NQ2T1qnuyRAAc1kskI8XVjKjZgZWoRrGGyRIB3GqmYc0IUbVTXM2IlvemIapRrGGyRAC3dWBlnxGi6qbYmhFOekZUc9T0yRIBsJmGSEaKCyPsM0JU8wwfPhxXrlzBjBkzkJycjPbt25eYLPH2mpC33noLKpUKb731FpKSkuDu7o6BAwfivffeq7pCsgMrkWwUF0ZMzTTsM0JUo9TkyRIB3Da0l2GEqLoprs8Im2mIqEKKm2l4Xxqiaqe4MMJ70xBRhRSxzwiRXJQXRjTFfUZkLggRWRf2GSGSjfLCiKkDK9MIEVmA08ETyUZ5YYSTnhFRRXBoL5FslBtGWDFCRJZgMw2RbBQcRphGiMgCrBkhko3iwohaxZoRIqoA9hkhko3iwggnPSOiCmEzDZFsFBdGbk16xqoRIrKAgWGESC6KCyMaNtMQUUVw0jMi2SgujGg1nIGViCqAfUaIZKO4MFLcgZX3piEii7DPCJFsFBdGNDePiB1YicgiHNpLJBsFhhHpkAysGSGi8jIaAGOh9D1rRoiqnfLCiNRKw+ngiaj8ivuLAOwzQiQD5YWR4hlYDQwjRFROxU00AKDRy1cOolpKgWHkZjMNa0aIqLxMw3rtAJXiLotENZ7izjpTB1b2GSGi8uKEZ0SyUlwY4dBeIrIY5xghkpXiwohp0jM20xBReXH2VSJZKS6M3LprL8MIEZUTJzwjkpXiwohGzWYaIrKQqZmGYYRIDooLI1o1701DRBYy3DaahoiqneLCiKmZhn1GiKi82ExDJCvFhRHTpGesGSGi8uJ9aYhkxTBCRFTcZ0TLZhoiOTCMEBFxaC+RrJQXRji0l4gsxRlYiWSluDCiVrMDKxFZiDUjRLJSXBjh0F4ishingyeSleLCiJqTnhGRpTi0l0hWigsjxX1GWDNCROXGob1EslJeGGGfESKyFGtGiGSl3DDCmhEiKi/2GSGSFcMIERGbaYhkxTBCRMRmGiJZKS+McNIzIrIUJz0jkpXywgg7sBKRpdhnhEhWig0jRqPMBSEi68EZWIlkpdgwUsQ0QkTlIYy33bWXYYRIDooLI+riSc8EINhUQ0R3Y8i/9T1rRohkobgwUnxvGkAKJEREd1RcKwKwzwiRTBQXRtS3hRE21RDRXRX3F1HbAmqNvGUhqqUUF0Y0t9eMMIsQ0d1wwjMi2SkujNzeTMPhvUR0V6bOq2yiIZKL4sJIcQdWADAYGEaI6C44rJdIdooLIxrWjBCRJTj7KpHsFBdGbssinBKeiO6ONSNEslNcGFGpVLdmYWXNCBHdDaeCJ5Kd4sIIcOtmeUWsGSGiu+Ede4lkp8wwYro/DcMIEd0Fh/YSyU7RYYR9RojorlgzQiQ7RYaR4k6sbKYhortinxEi2SkyjGg10mGxAysR3RWbaYhkp5W7AFWheOIzNtMQ0V15PgCobAD3znKXhKjWUmQYuVkxwjBCRHfn/aD0ICLZKLOZRi0dFsMIERFRzafIMKIurhlhnxEiIqIaT5FhRMM+I0RERFZDmWGE84wQERFZjQqFkQULFsDf3x96vR4hISHYu3fvHddPT0/HxIkT4e3tDZ1Oh6ZNm2Ljxo0VKnB5cAZWIiIi62HxaJoVK1YgIiICUVFRCAkJwbx58xAeHo5Tp07Bw8OjxPqFhYXo06cPPDw8sHr1avj4+ODChQuoU6dOZZS/VGrem4aIiMhqWBxG5s6di7Fjx2L06NEAgKioKGzYsAGLFi3CG2+8UWL9RYsW4dq1a9i1axdsbGwAAP7+/vdW6rvQam4207ADKxERUY1nUTNNYWEhYmNjERYWdusN1GqEhYUhJiam1G3Wr1+P0NBQTJw4EZ6enmjdujXef/99GAyGMvdTUFCAzMxMs4clijuwspmGiIio5rMojKSlpcFgMMDT09NsuaenJ5KTk0vd5ty5c1i9ejUMBgM2btyI6dOnY86cOXj33XfL3E9kZCRcXFxMDz8/P0uKCbWazTRERETWospH0xiNRnh4eODrr79GUFAQhg8fjjfffBNRUVFlbjNt2jRkZGSYHomJiRbtU8sOrEQ1kiWd33v27AmVSlXiMWDAgGosMRFVB4v6jLi5uUGj0SAlJcVseUpKCry8vErdxtvbGzY2NtBoNKZlLVq0QHJyMgoLC2Fra1tiG51OB51OZ0nRzJjuTcM+I0Q1hqWd39euXYvCwkLT86tXr6Jdu3YYOnRodRabiKqBRTUjtra2CAoKQnR0tGmZ0WhEdHQ0QkNDS92mS5cuOHv2LIxGo2nZ6dOn4e3tXWoQqQycZ4So5rm983vLli0RFRUFe3t7LFq0qNT1XV1d4eXlZXps3boV9vb2DCNECmRxM01ERAS++eYbLFmyBCdOnMD48eORk5NjGl0zYsQITJs2zbT++PHjce3aNUyZMgWnT5/Ghg0b8P7772PixImVdxT/wTBCVLNUpPP7f3333Xd4/PHH4eDgUOrr99rxnYjkY/HQ3uHDh+PKlSuYMWMGkpOT0b59e2zatMnUqTUhIQFq9a2M4+fnh82bN+Oll15C27Zt4ePjgylTpuD111+vvKP4D4YRoprlTp3fT548edft9+7di6NHj+K7774rc53IyEjMnj37nstKRNXP4jACAJMmTcKkSZNKfW379u0lloWGhmL37t0V2VWF8N40RMry3XffoU2bNggODi5znWnTpiEiIsL0PDMz0+KReEQkjwqFkZqueGgvO7AS1QwV6fxeLCcnB8uXL8fbb799x/XuteM7EclHkTfK49BeopqlIp3fi61atQoFBQV4+umnq7qYRCQTRdeMcNIzopojIiICI0eORKdOnRAcHIx58+aV6Pzu4+ODyMhIs+2+++47DB48GPXq1ZOj2ERUDRQZRthnhKjmsbTzOwCcOnUKO3fuxJYtW+QoMhFVE0WGEVMzDfuMENUolnZ+b9asGQTPYyLFU2SfETbTEBERWQ9FhhHetZeIiMh6KDOMaIr7jMhcECIiIrorZYYR3iiPiIjIaigzjJimg2fVCBERUU2n8DAic0GIiIjorhQdRji0l4iIqOZTZBhR3+wzUmRgGCEiIqrpFBlGOOkZERGR9VBkGDHdtZfzjBAREdV4igwjxUN7OQMrERFRzafIMKLVcAZWIiIia6HIMKLmpGdERERWQ5FhRHPzqNhnhIiIqOZTaBiRDothhIiIqOZTZhiRWmnYTENERGQFlBlGiof2ctIzIiKiGk+hYeRmMw1rRoiIiGo8hYYR6SuH9hIREdV8igwjak56RkREZDUUGUZMk56xmYaIiKjGU2QYMU16xpoRIiKiGk+RYaR4NA2baYiIiGo+RYYRrZr3piEiIrIWigwjvDcNERGR9VBkGDFNesaaESIiohqPYYSIiIhkxTBCREREslJmGOHQXiIiIquhzDCiZgdWIiIia6HoMMKhvURERDWfIsOImpOeERERWQ1FhpHiPiOsGSEiIqr5lBlG2GeEiIjIaig7jLBmhIiIqMZjGCEiIiJZMYwQERGRrJQZRoo7sDKLEBER1XjKDCOmob1GmUtCREREd6PoMMIsQkREVPMpMow429lAq1ah0GDE6ZQsuYtDREREd6DIMOKo0+KB5h4AgFX7EmUuDREREd2JIsMIAAzt5AcAWHcgCTcMbK8hIiKqqRQbRno2c4ebow5p2YX482Sq3MUhIiKiMig2jNho1Hi0ow8AYFXsRZlLQ0RERGVRbBgBgKFBvgCAP0+m4kpWgcylISIiotIoOow08XRCe786KDIK/HIgSe7iEBERUSkUHUYAYGgnqXZkxb5EGDklKxERUY2j+DAysF19OOq0OJuajT9OpMhdHCIiIvoPxYcRZ70NRoQ2BADM33YWQrB2hIiIqCZRfBgBgOe6BsDORoMjSRnYfvqK3MUhIiKi29SKMFLPUYen728AAJgffYa1I0RERDVIrQgjADC2eyPotGrsT0jHrrircheHiIiIbqo1YcTDSY8ngqXakS+2nZW5NERERFSs1oQRQKodAYCYc1eRls1J0IiIiGqCWhVGfOrYoaW3MwBg55k0mUtDREREQC0LIwDQvak7AGAHR9UQERHVCLUujPS4GUb+PnOFM7ISERHVALUujAQ1rAsHWw3Ssgtx/HKm3MUhIiKq9WpdGLHVqhEa6AaATTVEREQ1Qa0LIwDQoxn7jRAREdUUtTOMNJHCyP4L15GZfwNJ6XkYvzQWP8TEy1swIiKiWkgrdwHk0KCePQLcHHA+LQdfbY/Dqn0XkZZdgL9OX8GTwQ2g1dTKjEZERCSLWvtXt3hUzVfb40wToOUUGnAkKUPOYhEREdU6FQojCxYsgL+/P/R6PUJCQrB3795ybbd8+XKoVCoMHjy4IrutVMVhBAAebOlpmn8k5hzvW0NERFSdLA4jK1asQEREBGbOnIn9+/ejXbt2CA8PR2pq6h23i4+PxyuvvIJu3bpVuLCVqVsTNzwZ0gDT+jVH1NNB6HWzU2sMb6JHRERUrSwOI3PnzsXYsWMxevRotGzZElFRUbC3t8eiRYvK3MZgMOCpp57C7Nmz0ahRo3sqcGXRatR4/5E2eL5HINRqFUID6wEA9sVfR2GRUebSESmPpTWq6enpmDhxIry9vaHT6dC0aVNs3LixmkpLRNXJojBSWFiI2NhYhIWF3XoDtRphYWGIiYkpc7u3334bHh4eeO6558q1n4KCAmRmZpo9qlpTDye4Otgi74YBR5LSq3x/RLWJpTWqhYWF6NOnD+Lj47F69WqcOnUK33zzDXx8fKq55ERUHSwKI2lpaTAYDPD09DRb7unpieTk5FK32blzJ7777jt888035d5PZGQkXFxcTA8/Pz9LilkharUKIQGuANhUQ1TZLK1RXbRoEa5du4ZffvkFXbp0gb+/P3r06IF27dpVc8mJqDpU6WiarKwsPPPMM/jmm2/g5uZW7u2mTZuGjIwM0yMxMbEKS3lLcVMNO7ESVZ6K1KiuX78eoaGhmDhxIjw9PdG6dWu8//77MBgMZe5HjhpVIqocFs0z4ubmBo1Gg5SUFLPlKSkp8PLyKrF+XFwc4uPjMXDgQNMyo1Hqj6HVanHq1CkEBgaW2E6n00Gn01lStEoR2uhWv5GCIgN0Wk21l4FIae5Uo3ry5MlStzl37hy2bduGp556Chs3bsTZs2cxYcIE3LhxAzNnzix1m8jISMyePbvSy09EVc+imhFbW1sEBQUhOjratMxoNCI6OhqhoaEl1m/evDmOHDmCgwcPmh6DBg1Cr169cPDgwWppfrFEYw9HuDnaoqDIiIMJ6XIXh6jWMhqN8PDwwNdff42goCAMHz4cb775JqKiosrcRq4aVSK6dxbPwBoREYGRI0eiU6dOCA4Oxrx585CTk4PRo0cDAEaMGAEfHx9ERkZCr9ejdevWZtvXqVMHAEosrwlUKhVCGtXDhsOXsfzfROw8m4ZDFzPwUFtvDOtUs4ITkbWwtEYVALy9vWFjYwON5lbtZIsWLZCcnIzCwkLY2tqW2EauGlUiuncWh5Hhw4fjypUrmDFjBpKTk9G+fXts2rTJVAWbkJAAtdp6J3YNvRlG1h1IMi3bc+4qejR1h6ezXsaSEVmn22tUiyc8LK5RnTRpUqnbdOnSBT/99BOMRqPpenL69Gl4e3uXGkSIyLqphBBC7kLcTWZmJlxcXJCRkQFnZ+cq3VdqVj4e/XIXhABCAlxx/HImTiZn4Zn7G+KdwTWvNoeoOtzrObhixQqMHDkSCxcuNNWorly5EidPnoSnp6dZjSoAJCYmolWrVhg5ciRefPFFnDlzBs8++ywmT56MN998s1rKTET3rrznYa28Ud6deDjpsfP1B0zPY+Ku4olvdmP5vwkY170R/FztZSwdkXWytEbVz88PmzdvxksvvYS2bdvCx8cHU6ZMweuvvy7XIRBRFWLNSDk8/e0e7DybhqFBvvh4KOc5oNpH7nOwIqyxzERKU97z0Ho7d1Sjlx9sCgBYs/8i4q5ky1waIiIiZWEYKYcODeoirIUHjAKI3HgCVlCZREREZDUYRsrplfBmsNGo8MeJVCz6J17u4hARESkGw0g5NfdyxlsDWgKQakdiL1yXuURERETKwDBigRGhDTGgrTeKjAKTftqPazmFcheJiIjI6jGMWEClUuHDIW3RyN0BlzPyMW3tYbmLREREZPUYRizkqNNiwZMdoVGrsPlYCnaeSZO7SERERFaNYaQCWng745n7GwIA3v79GIoMRplLREREZL0YRiropbCmqGtvg9Mp2fh5b4LcxSEiIrJaDCMV5GJvg4g+0mRoc7aeRnouO7MSERFVBMPIPXgiuAGaeTohPfcG5mw5bfbazjNpCHpnK5bsipencERERFaCYeQeaDVqzBwozT3y4+4L+Oes1Jk1PbcQESsP4mpOIeZsOYXsgiI5i0lERFSjMYzco86N3fBUSAMAwKurDiEz/wam/3oMqVkFAIDM/CIsZ58SIiKiMjGMVIL/698CDVztcSkjH48v3I3fDl2CRq3C0/dLIeXbv8+jsIgjboiIiErDMFIJHHRazBnWDioVcPxyJgBgYs9ATH+oJTycdEjOzMevB5NkLiUREVHNxDBSSe7zd8W4bo0AAK3qO2PSA02g02rwXNcAAEDUjjgYjbzbLxER0X8xjFSi1/o2x4InO+KHZ4Nhq5U+2idDGsBJr0XclRxsPZEicwmJiIhqHoaRSqRRqzCgrTfqOepMy5z0NqbZWt/5/Tiy8m/IVTwiIqIaiWGkGozvGQg/VztcvJ6HmeuPyV0cIiKiGoVhpBo46W3w6bD2UKuAtfuT8NuhSygoMmDt/ouYuvwAYi9cl7uIREREstHKXYDaopO/KyY90ASfR5/B/609gtm/HUNatjSF/Majyfh0WHsMaOstcymJiIiqH2tGqtHkBxqjvV8dZBUUIS27EF7OegT7u6KwyIiJP+3Hwh1xEIIjboiIqHZhzUg10mrU+Orpjli44xzu83fFg608oVap8M7vx7F4Vzwi/3cSi/45j9BG9dC5sRsGtasPvY1G7mITERFVKZWwgn/FMzMz4eLigoyMDDg7O8tdnCqxaOd5fLjpJApum6m1uZcTFjzVEYHujjKWjMg6z0FrLDOR0pT3PGQzTQ3xbNcAHJr5IH4aE4IXH2gMN0dbnEzOwsD5O7Em9iIy82+wCYeIiBSJNSM1VGpmPiYvP4Dd566ZltloVPCpY4fX+jZH/zbs7ErVxxrPQWssM5HSsGbEynk467FszP2YGtYEznqpa88Ng0D81VxMWLYf7/5+HDcMvPkeERFZP3ZgrcE0ahWmhjXF1LCmyL9hwNWcQvwQE4+FO87h253ncehiOt4d3AbNvJxK3f5kciaW701E4rVcXLyeB61GhW9HdoK3i101HwkREVHZWDNiJfQ2GvjUscO0fi0Q9XQQnHRa/Bt/HeHz/sL4pbE4finTbH0hBF786QAW74pH9MlUnErJwrFLmfhqe5zZev/GX8P3/5yHgTfxIyIimTCMWKG+rb3w24tdMaCNN1Qq4H9Hk/HQ/L+x4/QV0zox567iTGo27G01eO+R1pg1sCUAYMW/iUjLLgAAXMkqwLPf/4vZvx3HT3suyHIsREREDCNWyt/NAQue6ojNU7ujR1N3GAUQufEEjDdrOH6MkcLFIx188FRIQ4zs7I92vi4oKDJiya54AMBHm04iq6AIADB362lk5PImfkREVP0YRqxcU08nfP54BzjptTiZnIXfj1xGckY+thxPAQA8EyrdMVilUuGFHoEAgB9iLuCfs2lYFXsRAODlrMf13BuYv+2MPAdBRES1GsOIArjY22Bct0YAgHlbT2Pp7gswGAWC/V3R3OvWUKoHW3khwM0BGXk38NySfwEAjwX54sPH2gIAFu+Kx7kr2dV/AEREVKsxjCjE6K4BcHWwxbm0HHy1Q+qkWlwrUkyjVmFcdym05N8wwlGnxWt9m6FHU3f0auaOIqPA+xtPcHI1IiKqVgwjCuGo02L8zWYYg1HAzVGH8FZeJdZ7tKMPPJx0AICpYU3g4aQHALw5oAU0ahX+OJGKgV/sxLaTKeUOJYnXcvHSioOIWHEQWfnsd0JERJZhGFGQp+9vaAoaTwb7wVZb8ser02rw7chOePvhVhjV2d+0vLGHE95+uBXsbTU4mpSJZxfvw5Pf7EH+DUOZ+8u/YcC8P04jbO4OrDuQhLUHkvD417txJaug0o+NiIiUi2FEQexsNZj/RAeMCG2IMTebY0rT1rcORoT6Q6sx//E/FdIQO19/AC/0CISdjQYx565i/aFLpb7HDYMRQ6NiMO+PMygoMiIkwBX1HGxx7FImhny1C/FpOZV6bEREpFwMIwoT0qge3n64NZz1NhXa3tXBFm/0a47JvZsAAH7em1DqeqtjL+JIUgac9Vp88WQHLB93P1aP7ww/VzskXMvFsIUxSM3Kr/BxEBFR7cEwQqV6LMgXWrUKBxLScTLZfHbX/BsGfB4tDQOeEtYUD7WtD5VKhQA3B6wZ3xlNPByRmlWAqcsPcmZXIiK6K4YRKpW7kw59WnoCAJbvTTR7bdmeBFzOyIe3ix5PhTQwe83DSY+vnu4IOxsNdsVdxRfbzlZbmYmIyDoxjFCZngiWgsba/RdNHVlzCorw5Z9SwJjcuwn0NpoS2zX2cMK7g1sDAD6LPo1dcWnVVGIiIrJGDCNUpq6N3eBb1w6Z+UXYeOQyjEaBr7bH4WpOIfzr2eOxIN8ytx0S5IuhQb4wCuD5H2KxaOd53DAYTa+nZuUjk8OAiYgIgFbuAlDNpVarMLyTH+ZsPY05W07jk82ncClD6pT6Up+msNHcOcu+/XBrnE/Lwb4L1/H278ex/N8EBDWsi5i4q4i/mgutWoUujd0woI03+rXxgtNtnW5zC4sw89dj6NCgLp78T1MQEREpC2tG6I6GdvKDRq1CUnoeLmXkw1GnxZiuAXiobf27bmtnq8GK50MR+Wgb1LW3wemUbPy8NxHxV3OhUgFFRoEdp6/gtTWHMXjBP8gtLDJt+3n0WayKvYgZvx7F+SoYJpyRdwMfbTqJhKu5lf7eRERkGdaM0B15uejx9sOtcCAhHWEtPNGzmXup/UTKolGr8ERwA/Rv7Y3vd51HTkER7m9UD/cFuCI1swD/O3IZS2LiEXclBx9tOoVZg1oh7ko2vtt5DoAUWD7efBJfPhVU6vvfMBjvWkNTmvnRZ/DtzvM4nZKNb0d2snh7IiKqPAwjdFdPhTTEUyEN777iHbjY22BqWFOzZc56G7zYuwna+dXBiEV7sXhXPPq29sKCP8/ihkGgra8LjiZlYOORZOxPuI6ODeqabb/1eAqmLD+AIR198c7NDrPlYTQKbDxyGQCw8+wV5N8wWBSwiIiocrGZhmTXvam7aeTOuB/24e8zabDVqPH54x1MnWQ/2HjS7F450SdSMGFZLHILDfhpbwIuZ+SVe38HL6ab+r7k3zDin7Mc7UNEJCeGEaoR/q9/c/jUkUbuAMC47o3g7+aAl/o0hU6rxt74a1iyKx4nkzOx6Wgyxi/djxsGAVuNGgajwNLdF8q9r42HL5s9/+NESqUeCxERWYZhhGoEJ70NPnqsLdQqwLeuHSb0ku5A7O1ih+e6BgAAZv12HH3n/Y0Xlsai0GBEv9ZemDu8HQDgpz0Jd7ypX7Hbm2iKJ2yLPpEK411mis3Mv4E1sReRV3j3fRARkWUYRqjG6NLYDf+b0h3rJnSBve2t7kwTejXGgDbeaOrpiHoOtrDRqPBoRx989ngH9G3lBZ86drieewPrD5Z+U7/bFTfRONhq8Hq/5nCw1SA1qwBHL2WUuY0QAlOXH8TLqw4hYuVBs+YiIiK6d+zASjVKMy+nEsscdVoseKqj6bkQAiqVyvR8RGhDRP7vJL7fFY+hnXzNXvuvDTebaMJaesJZb4PuTd3xv6PJ+ON4Ctr61il1my3HU7DtZCoA4H9Hk7FyXyKG38e5T4iIKgtrRsjq/DdsPH5fA9jZaHDicib2nr9W5nZGo8D/bjbR9G/jDQDo3UK6/84fJ1JL3SanoAiz1x8DADTzlILSrPXHce5Kdol1T6dk4ePNJ5GRx5lliYgswTBCVs/F3gaPdPQBAEz/9SjibgsKZ1OzMPPXo5j0036M/H6vqYmmR1N3AECvZu5Qq4DjlzORlF5yRM7n287gUkY+fOvaYe2EzugcWA95NwyYsvwgCotuTW8vhMCU5Qex4M84zP7tWBUfMRGRsjCMkCKM7xGIeg62OJ2SjYHzd2LZngv4v3VHED7vbyyJuYDfD1/G32ekIbz923ib5hWp56gzzV+y4bB5n5MTlzPx3d/nAQCzB7WCg06LucPao469DY4kZeCr7XGmdXecvoITlzMBAGv3J92xhoaIiMwxjJAi+LnaY+OUbri/kStyCw14c91R/LQnAQajQJ+Wnpg1sCU+eLQNvniyA2YOamW27YC2UpPNh5tO4ZcDSQCA2AvX8eQ3u1F0c/vi5hwvFz3eeViaYO3L7WeReE2aTr44mDjrpW5YM349iqLbbgxIRERlYwdWUgxPZz2WjbkfX2w7i8+3nUFrHxe82b8FggNc77jdM/c3xNGkTKzZfxEvrTyIf+OvYXXsRRQUGdHGxwWRj7YxW/+htt74aU8CYs5dxXsbTmBcj0bYc/4abDQqLB8Xiie/3Y2TyVn4IeYCOjeuhzWxF3Hxeh5mD2oFD2d9qWWI3HgC206m4ofnguHtYldpnwkRkTVQCSsYp5iZmQkXFxdkZGTA2dlZ7uKQFcgrNEBvo77jyJrbGY0Cs387hiUxtyZPC2vhgc+f6GA2zLjYqeQs9P/8bxiMAo3cHXDuSg6GBvni46Ht8PPeBExbewRqFXD79CXhrTyx8JmS98E5fDEdg774BwDw9P0N8O7gNiXWkZs1noPWWGYipSnvechmGlIkO1tNuYMIAKjVKswa1AovPtAYNhoVRnX2x8JnOpUaRABpCPIz90v36zl3Rbqr8PM9GgEAhnfyQzu/OjAKwEajQlgLD2jUKmw+loJtJ81nexVC4L0NJ0zPV/57Eck3p6onIqotGEaIblKpVHj5wWY4NrsvZg1qBY36zmHmpbCmcHWwBQA82NITjT2kob9qtQrfj7oPXz7VEXv/LwzfjrzPNIvszPXHzGZx3XYyFXvOX4OtVo0W3s4oNBjx9V/nTK+vib2IjzadREERZ34lIuViGCH6D1tt+U4LF3sbzBnWDp0D6+GNfs3NXnN1sEX/Nt6oezOsTOndBN4ueiRey8OX288CAIoMRkT+7yQA4NkuAZh28z1+2nsBadkFmLv1NF5edQhfbo/D3C2nK+vwiIhqHHZgJboHvZp5oFczj7uu56DTYubAlnhh6X58tT0Of59Jg95GjbOp2ahrb4PxPQPhrNeina8LDl3MwLCFMabmHwD4+u9z6NXcA/c3qnfH/cSn5aDQYERTz5Iz2RIR1VSsGSGqJuGtvDCwXX0UGQUOJqZj9zlpLpJJDzSBi50NVCoVJj3QBMCtfigzB7bEsE6+EAJ4eeUhZOXfQPSJFAz4/G+Ezd2Bq9kFpvdPyczHwPk7MXD+TlwqZQI3IqKaijUjRNVEpVLh88fb44UejZB4LQ8Xr+dCq1bhmVB/0zphLTzQzq8ODl9Mx/uPtMETwQ2QXVCEmHNXkXgtD70+2Y607ELT+u9tPIG5w9oDAD7cdBJZBUUAgGV7LuDVcPOmIyKimophhKgaqVQqtKrvglb1Xcp8fdmYEFzPKYSfqz0A6UaBc4a2x/CvY5CWXQidVo1HOvhgxb5ErN2fhMeCfGFno8Ha/Umm9/l5byJefKCJaaZZIqKajGGEqIZx1GnhqDM/NYMDXPHpsPY4cTkTIzv7o34dO2g1KizdnYC31h2F082ZXx/t4IPd567iUkY+Nhy+jCFBvnIcAhGRRdhnhMhKDO7gg2n9W6B+HWmG1lfDm8PdSYdzaTk4dDEDDrYavNG/OZ66Of/Jkph4WMGchkREDCNE1srFzgbTH2ppev5i7ybwcNLj8fv8YKtV4/DFDBxMTJevgERE5cQwQmTFBrb1xqjO/hjQ1huju/gDkO5EPLBtfQDAkl3xZutfzS7A66sPY9T3ezHvj9P46/QVZObfqLbyLliwAP7+/tDr9QgJCcHevXvLXHfx4sVQqVRmD72+9Hv7EJF1q1CfkQULFuDjjz9GcnIy2rVrh/nz5yM4OLjUdb/55hv88MMPOHr0KAAgKCgI77//fpnrE1H5qVTSNPb/NaqzP9bsv4hfDl6CWq3CtH4tEH81By/+dADJmdJ089tPXbn5HsCB6X1Qx962Ssu6YsUKREREICoqCiEhIZg3bx7Cw8Nx6tQpeHiUPleLs7MzTp06ZXpuyRT/5SYEkJtb+e9LpHT29tIFpBJYHEYsvaBs374dTzzxBDp37gy9Xo8PP/wQDz74II4dOwYfH59KOQgiMtfG1wXPd2+EhX+dw9r9SdhyLAV5NwwwGAUC3R3wRHADHE3KwP6EdKhUqPIgAgBz587F2LFjMXr0aABAVFQUNmzYgEWLFuGNN94odRuVSgUvL69yvX9BQQEKCm7Nu5KZmVm+guXmAo6O5VuXiG7JzgYcHCrnvYSFgoODxcSJE03PDQaDqF+/voiMjCzX9kVFRcLJyUksWbKk3PvMyMgQAERGRoalxSWq1Q4kXBcD5/8tGr7+u2j4+u9iys/7RXb+DbN1cgpulLH1Lfd6DhYUFAiNRiPWrVtntnzEiBFi0KBBpW7z/fffC41GIxo0aCB8fX3FoEGDxNGjR8vcx8yZMwWAEo+7ljk7WwipfoQPPviw5JGdfddzv7zXDotqRgoLCxEbG4tp06aZlqnVaoSFhSEmJqZc75Gbm4sbN27A1dW1zHUq/B8OEZlp71cH6yZ0we+HL8FWo0bf1l4lmjrKujNxZUpLS4PBYICnp6fZck9PT5w8ebLUbZo1a4ZFixahbdu2yMjIwCeffILOnTvj2LFj8PUtOWR52rRpiIiIMD3PzMyEn5/f3Qtnby/9h0dElrG3r7S3sugqVJELyn+9/vrrqF+/PsLCwspcJzIyErNnz7akaERUBo1ahYfbW1+TaGhoKEJDQ03PO3fujBYtWmDhwoV45513Sqyv0+mg0+ks35FKVXlVzURUIdU6muaDDz7A8uXLsW7dujv2ip82bRoyMjJMj8TExGosJRFVNjc3N2g0GqSkpJgtT0lJKXefEBsbG3To0AFnz56tiiISkYwsCiP3ckH55JNP8MEHH2DLli1o27btHdfV6XRwdnY2exCR9bK1tUVQUBCio6NNy4xGI6Kjo81qP+7EYDDgyJEj8Pb2rqpiEpFMLAojFb2gfPTRR3jnnXewadMmdOrUqeKlJSKrFRERgW+++QZLlizBiRMnMH78eOTk5JhG14wYMcKsP9rbb7+NLVu24Ny5c9i/fz+efvppXLhwAWPGjJHrEIioiljccy0iIgIjR45Ep06dEBwcjHnz5pW4oPj4+CAyMhIA8OGHH2LGjBn46aef4O/vj+TkZACAo6MjHDmcjqjWGD58OK5cuYIZM2YgOTkZ7du3x6ZNm0x90BISEqBW3/r/6Pr16xg7diySk5NRt25dBAUFYdeuXWjZsmVZuyAiK6USQghLN/riiy9Mk561b98en3/+OUJCQgAAPXv2hL+/PxYvXgwA8Pf3x4ULF0q8x8yZMzFr1qxy7S8zMxMuLi7IyMhgkw2RDKzxHLTGMhMpTXnPwwqFkerGiwqRvKzxHLTGMhMpTXnPQ96bhoiIiGTFMEJERESyYhghIiIiWTGMEBERkawYRoiIiEhWDCNEREQkK4YRIiIiklXV3zu8EhRPhZKZmSlzSYhqp+JzzwqmJTLhdYNIfuW9dlhFGMnKygIA+Pn5yVwSototKysLLi4uchejXHjdIKo57nbtsIoZWI1GIy5dugQnJyeoVKoy18vMzISfnx8SExMVP+NibTpWoHYdb008ViEEsrKyUL9+fbP7x9Rk5b1uADXzM68qPFblqonHW95rh1XUjKjVavj6+pZ7fWdn5xrzg6hqtelYgdp1vDXtWK2lRqSYpdcNoOZ95lWJx6pcNe14y3PtsI5/cYiIiEixGEaIiIhIVooKIzqdDjNnzoROp5O7KFWuNh0rULuOtzYda01Rmz5zHqtyWfPxWkUHViIiIlIuRdWMEBERkfVhGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrxYSRBQsWwN/fH3q9HiEhIdi7d6/cRaoUkZGRuO++++Dk5AQPDw8MHjwYp06dMlsnPz8fEydORL169eDo6IghQ4YgJSVFphJXng8++AAqlQpTp041LVPSsSYlJeHpp59GvXr1YGdnhzZt2mDfvn2m14UQmDFjBry9vWFnZ4ewsDCcOXNGxhIrkxKvHbxuKPe6ASj02iEUYPny5cLW1lYsWrRIHDt2TIwdO1bUqVNHpKSkyF20exYeHi6+//57cfToUXHw4EHRv39/0aBBA5GdnW1a54UXXhB+fn4iOjpa7Nu3T9x///2ic+fOMpb63u3du1f4+/uLtm3biilTppiWK+VYr127Jho2bChGjRol9uzZI86dOyc2b94szp49a1rngw8+EC4uLuKXX34Rhw4dEoMGDRIBAQEiLy9PxpIri1KvHbxuKPO6IYRyrx2KCCPBwcFi4sSJpucGg0HUr19fREZGyliqqpGamioAiB07dgghhEhPTxc2NjZi1apVpnVOnDghAIiYmBi5inlPsrKyRJMmTcTWrVtFjx49TBcVJR3r66+/Lrp27Vrm60ajUXh5eYmPP/7YtCw9PV3odDrx888/V0cRa4Xacu3gdUM5x6rUa4fVN9MUFhYiNjYWYWFhpmVqtRphYWGIiYmRsWRVIyMjAwDg6uoKAIiNjcWNGzfMjr958+Zo0KCB1R7/xIkTMWDAALNjApR1rOvXr0enTp0wdOhQeHh4oEOHDvjmm29Mr58/fx7Jyclmx+ri4oKQkBCrO9aaqjZdO3jdUM6xKvXaYfVhJC0tDQaDAZ6enmbLPT09kZycLFOpqobRaMTUqVPRpUsXtG7dGgCQnJwMW1tb1KlTx2xdaz3+5cuXY//+/YiMjCzxmpKO9dy5c/jqq6/QpEkTbN68GePHj8fkyZOxZMkSADAdT234vZZLbbl28LqhrGNV6rVDK3cBqPwmTpyIo0ePYufOnXIXpUokJiZiypQp2Lp1K/R6vdzFqVJGoxGdOnXC+++/DwDo0KEDjh49iqioKIwcOVLm0pGS8LqhLEq9dlh9zYibmxs0Gk2JntEpKSnw8vKSqVSVb9KkSfj999/x559/wtfX17Tcy8sLhYWFSE9PN1vfGo8/NjYWqamp6NixI7RaLbRaLXbs2IHPP/8cWq0Wnp6eijlWb29vtGzZ0mxZixYtkJCQAACm41H677WcasO1g9cNZV03AOVeO6w+jNja2iIoKAjR0dGmZUajEdHR0QgNDZWxZJVDCIFJkyZh3bp12LZtGwICAsxeDwoKgo2Njdnxnzp1CgkJCVZ3/L1798aRI0dw8OBB06NTp0546qmnTN8r5Vi7dOlSYqjl6dOn0bBhQwBAQEAAvLy8zI41MzMTe/bssbpjramUfO3gdUOZ1w1AwdcOuXvQVobly5cLnU4nFi9eLI4fPy7GjRsn6tSpI5KTk+Uu2j0bP368cHFxEdu3bxeXL182PXJzc03rvPDCC6JBgwZi27ZtYt++fSI0NFSEhobKWOrKc3uveCGUc6x79+4VWq1WvPfee+LMmTNi2bJlwt7eXixdutS0zgcffCDq1Kkjfv31V3H48GHx8MMP1/jhedZGqdcOXjeUed0QQrnXDkWEESGEmD9/vmjQoIGwtbUVwcHBYvfu3XIXqVIAKPXx/fffm9bJy8sTEyZMEHXr1hX29vbikUceEZcvX5av0JXovxcVJR3rb7/9Jlq3bi10Op1o3ry5+Prrr81eNxqNYvr06cLT01PodDrRu3dvcerUKZlKq1xKvHbwuqHc64YQyrx2qIQQQp46GSIiIiIF9BkhIiIi68YwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMEJERESyYhghIiIiWf0/4hknWFwSO+wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Creating subplot\n",
        "fig, (ax1, ax2) = plt.subplots(1,2)\n",
        "\n",
        "# Loss over epochs\n",
        "ax1.plot(range(len(history.history['loss'])), history.history['loss'])\n",
        "ax1.set_title('Loss function over epochs')\n",
        "ax2.plot(range(len(history.history['loss'])), history.history['accuracy'], color = 'orange')\n",
        "ax2.plot(range(len(history.history['loss'])), np.ones(70)*0.5, color = 'red')\n",
        "ax2.set_title('Accuracy over epochs')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dMIwIKIWl8kG",
        "outputId": "5c12220f-273c-48de-f0b1-a8e9e8c15bd3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │     <span style=\"color: #00af00; text-decoration-color: #00af00\">177,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m51,264\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m819,456\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_10 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │     \u001b[38;5;34m177,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_11 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │           \u001b[38;5;34m4,098\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">358,688,198</span> (1.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m358,688,198\u001b[0m (1.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,343,106</span> (684.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,343,106\u001b[0m (684.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,343,108</span> (684.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m179,343,108\u001b[0m (684.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary() #printing model summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edf8xnV7mAQK"
      },
      "source": [
        "The summary displays the output shapes for each layer and the number of parameters. We can see the output shape for the first layer is (None, 400,400,3) where 400 is both the width and height, while 3 represents the RGB color. In the last dense layer, however, the output shape is (None, 2), where 2 represents the 2 classes for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2w2COyVDmWk"
      },
      "source": [
        "Next, we will calculate the predictions from the model using .predict and calculate the loss and accuracy from the test images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnuZJGtDl9PA",
        "outputId": "9815196f-0457-484e-9d19-6610aa6720f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step\n",
            "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9007 - loss: 0.3525\n",
            "\n",
            "Validation Loss:  0.358897864818573\n",
            "\n",
            "Validation Accuracy:  90.0 %\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(testing)  # Running model on the test dataset\n",
        "val_loss, val_acc = model.evaluate(testing) # Obtaining Loss and Accuracy on the val dataset\n",
        "\n",
        "print('\\nValidation Loss: ', val_loss)\n",
        "print('\\nValidation Accuracy: ', np.round(val_acc * 100), '%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1U_51h5o-XjxwRxXFg3vMUplvGq6AFr1y",
      "authorship_tag": "ABX9TyMkQ/OyEHIh1KjKwYQJJENc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}